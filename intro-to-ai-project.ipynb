{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2510329,"sourceType":"datasetVersion","datasetId":1520310}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# Check if CUDA is available\nif torch.cuda.is_available():\n    device = torch.device(\"cuda:0\")  # Select GPU 0\n    print(f\"Using device: {torch.cuda.get_device_name(device)}\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"CUDA not available, using CPU\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ntrain_df = pd.read_csv(\"/kaggle/input/twitter-entity-sentiment-analysis/twitter_training.csv\")\n\ntest_df = pd.read_csv(\"/kaggle/input/twitter-entity-sentiment-analysis/twitter_validation.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cleaning the Training Set","metadata":{}},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.columns = ['id', 'game', 'sentiment', 'content']\n\n# Drop unnecessary column (filled with None values)\ntrain_df = train_df[['id', 'game', 'sentiment', 'content']]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df = train_df.drop(columns=['id', 'game'])\n\ntrain_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(len(train_df))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nan_values = train_df.isna().sum()\nduplicate_values = train_df.duplicated().sum()\n\nnan_values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove NaN values\ntrain_df = train_df.dropna()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"duplicate_values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove duplicate rows\ntrain_df = train_df.drop_duplicates()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print unique sentiment names\nunique_sentiments = train_df['sentiment'].unique()\nunique_sentiments","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace 'Irrelevant' with 'Neutral'\ntrain_df['sentiment'] = train_df['sentiment'].replace('Irrelevant', 'Neutral')\n\n# Calculate sentiment distribution\nsentiment_distribution = train_df['sentiment'].value_counts()\n\n# Print sentiment distribution\nsentiment_distribution","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for NaN values after cleaning\nnan_check = train_df.isna().sum()\nprint(\"NaN values after cleaning:\")\nprint(nan_check)\n\n# Check for duplicate rows after cleaning\nduplicate_check = train_df.duplicated().sum()\nprint(\"\\nDuplicate rows after cleaning:\")\nprint(duplicate_check)\n\n# Verify the sentiment distribution\nprint(\"\\nSentiment distribution after cleaning:\")\nprint(train_df['sentiment'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove duplicate rows\ntrain_df = train_df.drop_duplicates()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"duplicate_check = train_df.duplicated().sum()\nprint(\"\\nDuplicate rows after cleaning:\")\nprint(duplicate_check)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Cleaning the Test Set","metadata":{}},{"cell_type":"code","source":"test_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.columns = ['id', 'game', 'sentiment', 'content']\n\n# Drop unnecessary column (filled with None values)\ntest_df = test_df[['id', 'game', 'sentiment', 'content']]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df = test_df.drop(columns=['id', 'game'])\n\ntest_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"nan_values = test_df.isna().sum()\nduplicate_values = test_df.duplicated().sum()\n\nnan_values, duplicate_values","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove NaN values\ntest_df = test_df.dropna()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Remove duplicate rows\ntest_df = test_df.drop_duplicates()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print unique sentiment names\nunique_sentiments = test_df['sentiment'].unique()\nunique_sentiments","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Replace 'Irrelevant' with 'Neutral'\ntest_df['sentiment'] = test_df['sentiment'].replace('Irrelevant', 'Neutral')\n\n# Calculate sentiment distribution\nsentiment_distribution = test_df['sentiment'].value_counts()\n\n# Print sentiment distribution\nsentiment_distribution","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check for NaN values after cleaning\nnan_check = test_df.isna().sum()\nprint(\"NaN values after cleaning:\")\nprint(nan_check)\n\n# Check for duplicate rows after cleaning\nduplicate_check = test_df.duplicated().sum()\nprint(\"\\nDuplicate rows after cleaning:\")\nprint(duplicate_check)\n\n# Verify the sentiment distribution\nprint(\"\\nSentiment distribution after cleaning:\")\nprint(test_df['sentiment'].value_counts())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_df.head(10)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"len(train_df), len(test_df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Train / Val Set\nfrom sklearn.model_selection import train_test_split\n\nX = train_df['content']\ny = train_df['sentiment']\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, y, test_size=0.1, random_state=42, stratify=y  \n)\n\nprint(f\"Training Set: {len(X_train)} examples\")\nprint(f\"Validation Set: {len(X_val)} examples\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test Set\nX_test = test_df['content']  \ny_test = test_df['sentiment']  ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Test Set: {len(X_test)} examples\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"reference_reviews = [\"@GameDevStudio The new patch completely ruined the gameplay. Frame drops everywhere - unplayable!\",\n                    \"Not sure if I should spend my money on this game, looks fun but a bit skeptical. Any thoughts?\",\n                    \"Big thanks to @ConsoleBrand for their amazing customer support! My console is back to working perfectly.\",\n                    \"Had to cancel my order because the delivery was delayed for the third time. Frustrating.\",\n                    \"Absolutely loved the new RPG! Stunning graphics, deep story, and engaging gameplay.\"]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing for the Un-finetuned Model","metadata":{}},{"cell_type":"code","source":"import torch\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification\nfrom sklearn.metrics import classification_report\nfrom torch.utils.data import DataLoader, TensorDataset\nimport pandas as pd\n\n# Initialize tokenizer and model\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\nmodel.to(device)\n\nmax_length = 64  \ndef tokenize_data(texts, tokenizer, max_length=64):\n    return tokenizer(\n        list(texts),\n        padding='max_length',\n        truncation=True,\n        max_length=max_length,\n        return_tensors=\"pt\"\n    )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Tokenize validation set\nX_val_tokenized = tokenize_data(X_val, tokenizer, max_length=max_length)\n\n# Tokenize test set\nX_test_tokenized = tokenize_data(X_test, tokenizer, max_length=max_length)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Label mapping for sentiments\nlabel_mapping = {'Positive': 0, 'Negative': 1, 'Neutral': 2}\n\n# Encode validation labels\ny_val_encoded = y_val.map(label_mapping).to_numpy()\ny_val_tensor = torch.tensor(y_val_encoded, dtype=torch.long)\n\n# Encode test labels\ny_test_encoded = y_test.map(label_mapping).to_numpy()\ny_test_tensor = torch.tensor(y_test_encoded, dtype=torch.long)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Print validation labels info\nprint(f\"Validation Labels Shape: {y_val_tensor.shape}\")\nprint(f\"Validation Labels (First 5): {y_val_tensor[:5]}\")\n\n# Print test labels info\nprint(f\"Test Labels Shape: {y_test_tensor.shape}\")\nprint(f\"Test Labels (First 5): {y_test_tensor[:5]}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Validation dataset and dataloader\nbatch_size = 8\nval_dataset = TensorDataset(\n    X_val_tokenized['input_ids'], \n    X_val_tokenized['attention_mask'], \n    y_val_tensor\n)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\n\n# Test dataset and dataloader\ntest_dataset = TensorDataset(\n    X_test_tokenized['input_ids'], \n    X_test_tokenized['attention_mask'], \n    y_test_tensor\n)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verify DataLoader\nfor batch in val_loader:\n    input_ids, attention_mask, labels = batch\n    print(\"Validation Input IDs:\", input_ids.shape)\n    print(\"Validation Attention Mask:\", attention_mask.shape)\n    print(\"Validation Labels:\", labels.shape)\n    break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"First input IDs:\", input_ids[0])\nprint(\"First attention mask:\", attention_mask[0])\nprint(\"First label:\", labels[0])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation function for validation and test sets\ndef evaluate_model(loader, target_names):\n    model.eval()\n    all_predictions = []\n    all_labels = []\n    \n    with torch.no_grad():\n        for batch in loader:\n            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n            \n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            \n            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n            all_predictions.extend(predictions)\n            all_labels.extend(labels.cpu().numpy())\n    \n    # Generate classification report\n    report = classification_report(\n        all_labels, \n        all_predictions, \n        target_names=target_names, \n        output_dict=True, \n        zero_division=0\n    )\n    return pd.DataFrame(report).transpose()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate on validation set\nval_report = evaluate_model(val_loader, target_names=['Positive', 'Negative', 'Neutral'])\nprint(\"Validation Performance:\")\nprint(val_report.round(2))\n\n# Evaluate on test set\ntest_report = evaluate_model(test_loader, target_names=['Positive', 'Negative', 'Neutral'])\nprint(\"Test Performance:\")\nprint(test_report.round(2))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to classify custom reviews\nlabel_mapping = {0: 'Positive', 1: 'Negative', 2: 'Neutral'}\n\ndef classify_reviews(reviews):\n    inputs = tokenizer(\n        reviews,\n        padding='max_length',\n        truncation=True,\n        max_length=64,\n        return_tensors=\"pt\"\n    ).to(device)\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n\n    sentiments = [label_mapping[pred] for pred in predictions]\n    return sentiments","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predicted_sentiments = classify_reviews(reference_reviews)\n\n# Display predictions\nfor review, sentiment in zip(reference_reviews, predicted_sentiments):\n    print(f\"Review: {review}\")\n    print(f\"Predicted Sentiment: {sentiment}\\n\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Finetuning the DistillBert Model","metadata":{}},{"cell_type":"code","source":"import gc\nimport torch\n\n# Delete the un-finetuned tokenizer and model\ndel tokenizer\ndel model\n\n# Clear GPU memory\ntorch.cuda.empty_cache()\n\n# Collect garbage\ngc.collect()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW, get_scheduler\nfrom sklearn.metrics import classification_report\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom torch.nn import CrossEntropyLoss\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom tqdm import tqdm\nimport pandas as pd\n\n# Initialize tokenizer and fine-tuned model\ntokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\nmodel = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=3)\nmodel.to(device)\n\n# Tokenization function\ndef tokenize_data(texts, tokenizer, max_length=64):\n    return tokenizer(\n        list(texts),\n        padding='max_length',\n        truncation=True,\n        max_length=max_length,\n        return_tensors=\"pt\"\n    )\n\n# Tokenize datasets\nX_train_tokenized = tokenize_data(X_train, tokenizer)\nX_val_tokenized = tokenize_data(X_val, tokenizer)\nX_test_tokenized = tokenize_data(X_test, tokenizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Label mapping and encoding\nlabel_mapping = {'Positive': 0, 'Negative': 1, 'Neutral': 2}\ny_train_encoded = torch.tensor(y_train.map(label_mapping).to_numpy(), dtype=torch.long)\ny_val_encoded = torch.tensor(y_val.map(label_mapping).to_numpy(), dtype=torch.long)\ny_test_encoded = torch.tensor(y_test.map(label_mapping).to_numpy(), dtype=torch.long)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Create TensorDatasets\ntrain_dataset = TensorDataset(\n    X_train_tokenized['input_ids'], \n    X_train_tokenized['attention_mask'], \n    y_train_encoded\n)\nval_dataset = TensorDataset(\n    X_val_tokenized['input_ids'], \n    X_val_tokenized['attention_mask'], \n    y_val_encoded\n)\ntest_dataset = TensorDataset(\n    X_test_tokenized['input_ids'], \n    X_test_tokenized['attention_mask'], \n    y_test_encoded\n)\n\n# DataLoaders\nbatch_size = 16\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Class weights for imbalanced datasets\nclass_weights = compute_class_weight(\n    class_weight='balanced',\n    classes=[0, 1, 2],\n    y=y_train.map(label_mapping)\n)\nclass_weights = torch.tensor(class_weights, dtype=torch.float).to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Optimizer and scheduler\noptimizer = AdamW(model.parameters(), lr=5e-5)\nnum_training_steps = len(train_loader) * 3  # 3 epochs\n\n# Define warm-up steps (e.g., 10% of training steps)\nwarm_up_steps = int(0.1 * num_training_steps)\n\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=warm_up_steps,\n    num_training_steps=num_training_steps\n)\n\n# Loss function\nloss_fn = CrossEntropyLoss(weight=class_weights)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Training loop\ntrain_loss_history = []\ntrain_accuracy_history = []\nepochs = 3\n\nfor epoch in range(epochs):\n    print(f\"Epoch {epoch + 1}/{epochs}\")\n    model.train()\n    loop = tqdm(train_loader, leave=True)\n\n    epoch_loss = 0\n    correct = 0\n    total = 0\n\n    for batch in loop:\n        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n\n        # Forward pass\n        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n        logits = outputs.logits\n        loss = loss_fn(logits, labels)\n\n        # Backward pass\n        loss.backward()\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n\n        epoch_loss += loss.item()\n        predictions = torch.argmax(logits, dim=-1)\n        correct += (predictions == labels).sum().item()\n        total += labels.size(0)\n\n        loop.set_postfix(loss=loss.item(), accuracy=correct / total)\n\n    train_loss_history.append(epoch_loss / len(train_loader))\n    train_accuracy_history.append(correct / total)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Plot training loss and accuracy\nplt.figure(figsize=(12, 5))\n\n# Plot loss\nplt.subplot(1, 2, 1)\nplt.plot(train_loss_history, label='Training Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Loss')\nplt.legend()\n\n# Plot accuracy\nplt.subplot(1, 2, 2)\nplt.plot(train_accuracy_history, label='Training Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluation function\ndef evaluate_model(model, loader):\n    model.eval()\n    all_predictions, all_labels = [], []\n\n    with torch.no_grad():\n        for batch in loader:\n            input_ids, attention_mask, labels = [x.to(device) for x in batch]\n            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n            logits = outputs.logits\n            predictions = torch.argmax(logits, dim=-1)\n\n            all_predictions.extend(predictions.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    return classification_report(all_labels, all_predictions, target_names=['Positive', 'Negative', 'Neutral'], zero_division=0)\n\n# Evaluate on validation and test sets\nprint(\"Validation Results:\")\nprint(evaluate_model(model, val_loader))\n\nprint(\"\\nTest Results:\")\nprint(evaluate_model(model, test_loader))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Evaluate specific user reviews\nreference_reviews = [\"@GameDevStudio The new patch completely ruined the gameplay. Frame drops everywhere - unplayable!\",\n                    \"Not sure if I should spend my money on this game, looks fun but a bit skeptical. Any thoughts?\",\n                    \"Big thanks to @ConsoleBrand for their amazing customer support! My console is back to working perfectly.\",\n                    \"Had to cancel my order because the delivery was delayed for the third time. Frustrating.\",\n                    \"Absolutely loved the new RPG! Stunning graphics, deep story, and engaging gameplay.\"]\n\ninputs = tokenize_data(reference_reviews, tokenizer)\ninputs = {key: val.to(device) for key, val in inputs.items()}\n\nmodel.eval()\nwith torch.no_grad():\n    outputs = model(**inputs)\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n\n# Map predictions to sentiments\npredicted_sentiments = [list(label_mapping.keys())[pred] for pred in predictions]\nfor review, sentiment in zip(reference_reviews, predicted_sentiments):\n    print(f\"Review: {review}\")\n    print(f\"Predicted Sentiment: {sentiment}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Save Model","metadata":{}},{"cell_type":"code","source":"from transformers import DistilBertTokenizer\n\n# Define the directory where the model will be saved\nsave_directory = 'distilbert_finetuned_3_epochs'\n\n# Save the model\nmodel.save_pretrained(save_directory)\n\n# Save the tokenizer\ntokenizer.save_pretrained(save_directory)\n\n# Save the model configuration (optional, but usually included with `save_pretrained`)\nmodel.config.save_pretrained(save_directory)\n\nprint(f\"Model, tokenizer, and configuration saved to {save_directory}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import login\n\n# Log in to Hugging Face\n# This will prompt you for your Hugging Face token, which you can find at: https://huggingface.co/settings/tokens\nlogin()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from huggingface_hub import create_repo, upload_folder\n\nusername = \"Savoxism\"  \nrepo_name = \"distilbert_sentiment_analysis_final\" \nrepo_id = f\"{username}/{repo_name}\"\n\n# Create the repository\ncreate_repo(repo_id, exist_ok=True)\n\n# Upload the model\nmodel_path = \"/kaggle/working/distilbert_finetuned_3_epochs\" \nupload_folder(\n    repo_id=repo_id,\n    folder_path=model_path,\n    commit_message=\"Upload final fine-tuned DistilBERT for sentiment analysis\",\n)\nprint(f\"Model uploaded to: https://huggingface.co/{repo_id}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Testing Model","metadata":{}},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T07:25:27.825041Z","iopub.execute_input":"2024-12-23T07:25:27.825352Z","iopub.status.idle":"2024-12-23T07:25:30.990482Z","shell.execute_reply.started":"2024-12-23T07:25:27.825314Z","shell.execute_reply":"2024-12-23T07:25:30.989590Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n\n# Define the path to the fine-tuned model\nfine_tuned_model_dir = 'Savoxism/distilbert_sentiment_analysis_final'  # Update this to the directory where your model is saved\n\n# Load the fine-tuned model and tokenizer\nmodel = DistilBertForSequenceClassification.from_pretrained(fine_tuned_model_dir)\ntokenizer = DistilBertTokenizer.from_pretrained(fine_tuned_model_dir)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\nmodel.eval()  # Set the model to evaluation mode","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T07:25:30.991611Z","iopub.execute_input":"2024-12-23T07:25:30.992041Z","iopub.status.idle":"2024-12-23T07:25:56.574250Z","shell.execute_reply.started":"2024-12-23T07:25:30.991995Z","shell.execute_reply":"2024-12-23T07:25:56.573321Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b818c7905a314c8d94495cbda776d7d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e79f35c51c24496b996e6b66ee00a44e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c321c3bc9d714d33a9934a45bf4a880e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29041dfa67634bf5a9d74b04c3863c7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"210b75c74d174e7bb688025e7965cb18"}},"metadata":{}},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): DistilBertSdpaAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=3, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"import torch\n\ndef classify_review(review, model, tokenizer, device, max_length=64):\n    # Tokenize the review\n    inputs = tokenizer(\n        review,\n        padding='max_length',\n        truncation=True,\n        max_length=max_length,\n        return_tensors=\"pt\"\n    ).to(device)\n\n    with torch.no_grad():\n        outputs = model(**inputs)\n        logits = outputs.logits\n        prediction = torch.argmax(logits, dim=-1).item()\n\n    label_mapping = {0: 'Positive', 1: 'Negative', 2: 'Neutral'}  # Ensure this matches your fine-tuned model\n    sentiment = label_mapping[prediction]\n    return sentiment","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T07:26:16.751487Z","iopub.execute_input":"2024-12-23T07:26:16.752302Z","iopub.status.idle":"2024-12-23T07:26:16.757430Z","shell.execute_reply.started":"2024-12-23T07:26:16.752266Z","shell.execute_reply":"2024-12-23T07:26:16.756519Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"review = input(\"Enter a review: \")\n\npredicted_sentiment = classify_review(review, model, tokenizer, device)\n\nprint(f\"\\nReview: {review}\")\nprint(f\"Predicted Sentiment: {predicted_sentiment}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T07:28:00.526366Z","iopub.execute_input":"2024-12-23T07:28:00.527122Z","iopub.status.idle":"2024-12-23T07:28:02.751885Z","shell.execute_reply.started":"2024-12-23T07:28:00.527090Z","shell.execute_reply":"2024-12-23T07:28:02.750991Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Enter a review:  The new patch fixed a lot of bugs, but it introduced new ones that are just as annoying\n"},{"name":"stdout","text":"\nReview: The new patch fixed a lot of bugs, but it introduced new ones that are just as annoying\nPredicted Sentiment: Negative\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}